_BASE_: "../../uniter_mm_understanding_base.yaml"

####################################### DATASETS #######################################
DATASETS:
  TRAIN: 'VQADataset'
  VAL: 'VQADataset'
  TEST: 'VQADataset'

###################################### DATALOADER ######################################
DATALOADER:
  TRAIN_BATCH_SIZE: 24
  TEST_BATCH_SIZE: 32
  NUM_WORKERS: 4
  FEATS_FOLDER: '../open_source_dataset/VQA/features/up_down'
  ANNO_FOLDER: '../open_source_dataset/VQA'
  SEQ_PER_SAMPLE:  1
  MAX_FEAT_NUM: 51

######################################### MODEL #########################################
MODEL:
  MAX_SEQ_LEN: 23
  WEIGHTS: '../pretrain/UNITER/UNITER.pth'

######################################### MM_PREDICTOR #########################################
  MM_PREDICTOR:
    LABELS_NUM: 3129

####################################### Optimizer #######################################
SOLVER:
  NAME: 'Adam'
  EPOCH: 20
  CHECKPOINT_PERIOD: 1
  EVAL_PERIOD: 1
  BASE_LR: 0.00005
  BIAS_LR_FACTOR: 1.0
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_NORM: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  MOMENTUM: 0.0
  DAMPENING: 0.0
  NESTEROV: 0.0
  BETAS: [0.9, 0.98]
  EPS: 1e-8
  GRAD_CLIP: 2.0
  GRAD_CLIP_TYPE: 'norm'
  NORM_TYPE: 2.0
  
####################################### lr scheduler ####################################### 
LR_SCHEDULER:
  NAME: 'WarmupMultiStepLR'
  STEPS: [10, 12]
  GAMMA: 0.2
  WARMUP: 4

####################################### losses ####################################### 
LOSSES:
  NAMES: ['BCEWithLogits']

INFERENCE:
  VOCAB: ''
  NAME: 'VQAEvaler'
  ID_KEY: 'question_id'
  VALUE: 'answer'
  VAL_ANNFILE: '../open_source_dataset/VQA/val_target.pkl'
  TEST_ANNFILE: ''
  GENERATION_MODE: False
  VAL_EVAL_START: -1
  TEST_EVAL_START: 10
